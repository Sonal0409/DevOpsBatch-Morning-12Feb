ReplicaSet:

---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: myrs
spec:
 replicas: 3
 selector:
  matchExpressions:
   - {key: type, operator: In, values: [webserver_1, webserver_2]}
 template:
  metadata:
   name: mypod
   labels:
    type: webserver_2
  spec:
   containers:
    - name: c1
      image: nginx

=======================
Deployment:
=======================

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginxpod
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest

==========================

HPA
=======================

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          resources:
            limits:
              cpu: 10m

===================
HPA YAML

              apiVersion: autoscaling/v1
              kind: HorizontalPodAutoscaler
              metadata:
                name: nginx-hpa
              spec:
                scaleTargetRef:
                  apiVersion: apps/v1
                  kind: Deployment
                  name: nginx
                minReplicas: 1
                maxReplicas: 10
                targetCPUUtilizationPercentage: 5

============
Service for HPA scenario:
=============


              apiVersion: v1
              kind: Service
              metadata:
                name: nginx-svc
              spec:
                type: ClusterIP  
                selector:
                  app: nginx
                ports:
                 - protocol: TCP
                   port: 80
                   targetPort: 80

================
Command to generate the load:

# kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://10.8.10.18:80; done"


==========================================================

Persistent Volume and Persistent Volume Claim:
=============================================
In class Notes:
Problem: 

 > whenever a pod is created, the container will store data 
 > if the pod is deleted , the containers data will be lost
So today we have to find the ways in which we can preserve the data of the container 

 -> preserve data of the container on the Cluster  --> Dev/Test Env -> same as docker
 
 -> preserve data of the container outside the cluster -> Prod Env -> external storage

Storage: Container Storage in Kubernetes 

Volumes in Kubernetes

Recap of volumes in Containers



1. Persistent Volume Claim => PVC -> always created manually
2. Persistent Volume => PV  => manually , dynamically

Manual creation of Volumes in K8s Cluster --> Volume of type -> HostPath --> CKA exam

1. Persistent Volume Claim => PVC
2. Persistent Volume => PV

Dynamic creation of Volumes outside the K8s Cluster -> --> Volume of type -> Persistentdisk --> real time use case

   > Container storge Interface
   > Storage StorageClass

Retain policy for Persistent Volume : 
============================================
Delete : Pod using the volume gets deleted then the volume also get deleted

Retain: Pod using the volume gets deleted but the volume still remains with data retained in the directory

Recycle: Pod using the volume gets deleted then the volume directly gets cleaned up


pdcsi -> It is container storage Interface Pod -> storage driver 

This pod comes by default when the cluster is created on GCP

If you create cluster on AWS --> EBSCSI
If you create cluster on Azure --> blobCSI

However we can also install our own CSI -> netapp, ceph,emc etc


StorageClass => it is not an object of kubernetes => It is just a configuration

StorageClass is like a permission that we give to kubernetes to use of CSI driver to create and manage 
the storage outside the Cluster

====================================================

# vim pv.yml

apiVersion: v1
kind: PersistentVolume
metadata:
 name: block-pv 
spec:
 storageClassName: manual
 capacity: 
  storage: 1Gi  
 accessModes:
  - ReadWriteOnce
 persistentVolumeReclaimPolicy: Recycle
 hostPath:    
  path: /tmp/data

# vim pvc.yml


apiVersion: v1
kind: PersistentVolumeClaim
metadata:
 name: pvc
spec:
 storageClassName: manual
 accessModes:
  - ReadWriteOnce  
 resources:
  requests:
   storage: 1Gi

# vim pod-pvc.yml

apiVersion: v1
kind: Pod
metadata:
 name: pod-pvc
spec:
 containers:
  - image: nginx
    name: c1
    volumeMounts:
     - mountPath: "/data"
       name: my-volume
 volumes:
  - name: my-volume
    persistentVolumeClaim:
     claimName: pvc

======================================================

Dynamic Provisioning 


# vim sc.yml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-ssd

# vim pvc-dynamic.yml

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sc-pvc 
spec:
  storageClassName: fast
  resources:
    requests:
      storage: 10Gi
  accessModes:
    - ReadWriteOnce

# vim pod-dynamic.yml

apiVersion: v1
kind: Pod
metadata:
 name: pod-pvc
spec:
 containers:
  - image: nginx
    name: c1
    volumeMounts:
     - mountPath: "/data"
       name: my-volume
 volumes:
  - name: my-volume
    persistentVolumeClaim:
     claimName: sc-pvc

================================
# kubectl get configmap

# kubectl create configmap dev-config --from-literal=app.mem=2048m

# kubectl get configmap

# kubectl get configmap dev-config -o yaml
# vim dev.properties
app.env:dev
app.mem=2048m
app.properties=dev.env.url
:wq!

# kubectl create configmap dev-config1 --from-file=dev.properties
# kubectl get configmap
# kubectl get configmap dev-config1 -o yaml

Use configmap for a pod

vim pod-configmap.yml

kind: Pod
apiVersion: v1
metadata:
name: pod-configmap
spec:
containers:
 - image: nginx
   name: c1
   volumeMounts:
    - name: config-volume
      mountPath: /etc/config
volumes:
 - name: config-volume
   configMap:
    name: dev-config1
restartPolicy: Never

:wq!

# kubectl apply -f pod-configmap.yml
# kubectl exec -it pod-configmap bash
# cd /etc/config

you will find the dev.properties file and configurations

Edit the configMAP

kubectl edit configmap -n <namespace> <configMapName> -o yaml

This opens up a vim editor with the configmap in yaml format. Now simply edit it and save it.

====================================

Secrets:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - image: mysql:8
          name: mysql
          env:
            - name: MYSQL_ROOT_PASSWORD
              value: root



===============

echo YWRtaW4= | base64 --decode


kind: Secret
apiVersion: v1
metadata:
   name: wp-mysql
data:
   password: "YWRtaW4="


   apiVersion: apps/v1
kind: Deployment
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - image: mysql:8
          name: mysql
          env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                   name: wp-mysql
                   key: password

=======================================

Helm:
==========================

> Now we have to create a new Helm chart using which we are going to deploy our Custom Docker image. Follow below commands to create a new helm Chart

# helm create webapp
# ls -al webapp

> By default, you will get a lot of files inside this helm chart but we are going to delete those so that we donâ€™t see error while deploying these.

# cd webapp/
# pwd
# cd templates/
# ls -al
# rm -rf *.yaml NOTES.txt tests ../values.yaml 
# ls -la

> Create deployment.yaml inside templates directory with below content

apiVersion: apps/v1

kind: Deployment

metadata:

  name: ais-ifm

  labels:

    app: ais

spec:

  replicas: 3

  selector:

    matchLabels:
      app: ais
      tier: web

  template:

    metadata:

      labels:
       app: ais
       tier: web

    spec:

      containers:

      - name: ais

        image: edu123/docker-image

        ports:

        - containerPort: 8090

        resources:

          limits:

            cpu: 1000m

            memory: 600Mi

          requests:

            cpu: 500m

            memory: 300Mi




Create a service YAMl
=======================

vim service.yml

---

apiVersion: v1

kind: Service

metadata:

 name: mysvc

spec:

 type: NodePort

 ports:

  - targetPort: 8080

    port: 8080

 selector:
  app: ais


[OPTIONAL]
You can check if your chart is correct or not

# cd ../..

# helm install mydemo webapp


> we will also push the helm charts folder to the git hub repo

come out of templates and webapp folder

> cd ../..

> you will be in the repo folder

Execute git commands to commit the webapp folder and push to github

# git add .
# git commit -m "done helm"
# git push origin master
username: 
password: personal access token
